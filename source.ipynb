{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING,PRE-PROCESSING AND EXTRECTING FEATURES OF THE IMAGES OF CIFAR-10 DATASET\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "data_folder = 'Dataset'  # Path to the folder containing images\n",
    "\n",
    "# Loading images from the folder\n",
    "image_files = [os.path.join(data_folder, f) for f in os.listdir(data_folder) if os.path.isfile(os.path.join(data_folder, f))]\n",
    "\n",
    "images = []\n",
    "features = []\n",
    "num_bins = 256\n",
    "\n",
    "for file in image_files:\n",
    "    with Image.open(file) as img:\n",
    "        # Resizing the image to 32x32 pixels\n",
    "        img_resized = img.resize((32, 32))\n",
    "        # Converting the image to a list of tuples (pixels)\n",
    "        img_data = list(img_resized.getdata())\n",
    "        \n",
    "        # Normalizing pixel values for the images\n",
    "        normalized_img_data = [(pixel[0] / 255.0, pixel[1] / 255.0, pixel[2] / 255.0) for pixel in img_data]\n",
    "        images.append(normalized_img_data)\n",
    "        \n",
    "        # Separating the pixel values for each channel (R, G, B)\n",
    "        # we seperate r,g,b for every image\n",
    "        r_values = [pixel[0] for pixel in img_data]\n",
    "        g_values = [pixel[1] for pixel in img_data]\n",
    "        b_values = [pixel[2] for pixel in img_data]\n",
    "        \n",
    "        # Calculating the histogram for each channel\n",
    "        # we loop num of bins time and calculate every colour(r,g,b) occurence\n",
    "        hist_r = [r_values.count(i) for i in range(num_bins)]\n",
    "        hist_g = [g_values.count(i) for i in range(num_bins)]\n",
    "        hist_b = [b_values.count(i) for i in range(num_bins)]\n",
    "        \n",
    "        # Concatenating the histograms to form a feature vector\n",
    "        feature = hist_r + hist_g + hist_b\n",
    "        features.append(feature)\n",
    "\n",
    "print(\"Number of images:\", len(images))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "# Initializing LSH\n",
    "num_perm = 128  # Number of permutations\n",
    "bands = 2  # Number of bands\n",
    "b = int(num_perm / bands)  # Calculate the number of rows per band\n",
    "lsh = MinHashLSH(num_perm=num_perm, params=(b, bands))\n",
    "\n",
    "# Creating MinHash objects for each feature vector\n",
    "minhashes = []\n",
    "for feature in features:\n",
    "    m = MinHash(num_perm=num_perm)\n",
    "    for value in feature:\n",
    "        m.update(str(value).encode('utf-8'))\n",
    "    minhashes.append(m)\n",
    "\n",
    "# Inserting MinHash objects into LSH\n",
    "for i, minhash in enumerate(minhashes):\n",
    "    lsh.insert(str(i), minhash)\n",
    "\n",
    "# Function to retrieve similar images given a query image\n",
    "def retrieve_similar_images(query_image_path, threshold=0.5):\n",
    "    with Image.open(query_image_path) as query_img:\n",
    "        # Resizing the query image to 32x32 pixels\n",
    "        query_img_resized = query_img.resize((32, 32))\n",
    "        # Converting the query image to a list of tuples (pixels)\n",
    "        query_img_data = list(query_img_resized.getdata())\n",
    "        \n",
    "        # Separating the pixel values for each channel (R, G, B)\n",
    "        query_r_values = [pixel[0] for pixel in query_img_data]\n",
    "        query_g_values = [pixel[1] for pixel in query_img_data]\n",
    "        query_b_values = [pixel[2] for pixel in query_img_data]\n",
    "        \n",
    "        # Calculating the histogram for each channel\n",
    "        query_hist_r = [query_r_values.count(i) for i in range(num_bins)]\n",
    "        query_hist_g = [query_g_values.count(i) for i in range(num_bins)]\n",
    "        query_hist_b = [query_b_values.count(i) for i in range(num_bins)]\n",
    "        \n",
    "        # Concatenating the histograms to form a feature vector\n",
    "        query_feature = query_hist_r + query_hist_g + query_hist_b\n",
    "\n",
    "        # Creating a MinHash object for the query image\n",
    "        query_minhash = MinHash(num_perm=num_perm)\n",
    "        for value in query_feature:\n",
    "            query_minhash.update(str(value).encode('utf-8'))\n",
    "\n",
    "        # Querying LSH with the MinHash of the query image\n",
    "        result = lsh.query(query_minhash)\n",
    "\n",
    "        # Filtering results based on Jaccard similarity threshold\n",
    "        similar_images = []\n",
    "        for r in result:\n",
    "            jaccard_similarity = query_minhash.jaccard(minhashes[int(r)])\n",
    "            if jaccard_similarity >= threshold:\n",
    "                similar_images.append(image_files[int(r)])\n",
    "\n",
    "        return similar_images\n",
    "\n",
    "# Example usage\n",
    "query_image_path = '001.png'\n",
    "similar_images = retrieve_similar_images(query_image_path)\n",
    "\n",
    "print(\"Similar images:\")\n",
    "for image_path in similar_images:\n",
    "    print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2 \n",
    "from sklearn.neighbors import LSHForest\n",
    "from PIL import Image\n",
    "\n",
    "# Defining parameters\n",
    "n_estimators = 10  # Number of base estimators in the ensemble\n",
    "n_candidates = 50  # Number of neighbors to consider for each query point\n",
    "num_bins = 256  # Number of bins for the histogram\n",
    "\n",
    "# Initializing LSHForest\n",
    "lsh_forest = LSHForest(n_estimators=n_estimators, n_candidates=n_candidates, n_neighbors=1, random_state=42)\n",
    "\n",
    "# Fit LSHForest to the feature vectors of normal images\n",
    "lsh_forest.fit(features)\n",
    "\n",
    "# Storing the representations of normal images in the LSH hash tables\n",
    "representations = lsh_forest.get_params(deep=True)\n",
    "\n",
    "# Load the new image and compute its histogram features\n",
    "new_image_path = 'image.jpg'\n",
    "new_image_features = []\n",
    "\n",
    "with Image.open(new_image_path) as img:\n",
    "    img_resized = img.resize((32, 32))\n",
    "    img_data = list(img_resized.getdata())\n",
    "\n",
    "    r_values = [pixel[0] for pixel in img_data]\n",
    "    g_values = [pixel[1] for pixel in img_data]\n",
    "    b_values = [pixel[2] for pixel in img_data]\n",
    "\n",
    "    hist_r = [r_values.count(i) for i in range(num_bins)]\n",
    "    hist_g = [g_values.count(i) for i in range(num_bins)]\n",
    "    hist_b = [b_values.count(i) for i in range(num_bins)]\n",
    "\n",
    "    new_image_features = hist_r + hist_g + hist_b\n",
    "\n",
    "# Query the LSH hash tables to find the nearest neighbors\n",
    "nearest_neighbors_indices = lsh_forest.kneighbors([new_image_features], return_distance=False)\n",
    "\n",
    "# Measuring the distance or dissimilarity between the new image and its nearest neighbors\n",
    "nearest_neighbors_distances = []\n",
    "for idx in nearest_neighbors_indices[0]:\n",
    "    distance = sum(abs(a - b) for a, b in zip(new_image_features, features[idx]))\n",
    "    nearest_neighbors_distances.append(distance)\n",
    "\n",
    "# Identifying the new image as an anomaly if its distance from the nearest neighbors exceeds a predefined threshold\n",
    "threshold = 100\n",
    "if max(nearest_neighbors_distances) > threshold:\n",
    "    print(\"Anomaly detected: The new image is an anomaly.\")\n",
    "else:\n",
    "    print(\"No anomaly detected: The new image is similar to the existing images.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
